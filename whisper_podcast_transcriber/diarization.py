import os
import torch
import whisperx
from whisperx import diarize

def run_transcribe_with_diarization(audio_path, output_dir, model_size="large-v3", skip_diarization=False, num_speakers=None):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    compute_type = "float16" if device == "cuda" else "float32"
    
    print(f"ğŸ”§ Using device: {device.upper()}")
    print(f"âš™ï¸  Compute type: {compute_type}")

    print("ğŸ¤– Loading Whisper model...")
    model = whisperx.load_model(model_size, device, compute_type=compute_type)
    print(f"âœ… Model '{model_size}' loaded successfully")
    
    print("ğŸ¤ Transcribing audio...")
    result = model.transcribe(audio_path)
    print(f"âœ… Transcription complete - {len(result['segments'])} segments found")

    print("ğŸ”— Loading alignment model...")
    model_a, metadata = whisperx.load_align_model(language_code=result["language"], device=device)
    print(f"âœ… Alignment model loaded for language: {result['language']}")
    
    print("âš¡ Aligning ASR with audio...")
    result = whisperx.align(result["segments"], model_a, metadata, audio_path, device)
    print("âœ… Audio alignment completed")

    if not skip_diarization:
        token = os.getenv("HUGGINGFACE_TOKEN")
        if not token:
            print("âš ï¸  Warning: HUGGINGFACE_TOKEN not set â€” diarization may fail.")
            print("ğŸ’¡ Set HUGGINGFACE_TOKEN environment variable for speaker diarization")
            print("â© Continuing without speaker diarization...")
        else:
            print("ğŸ§  Loading speaker diarization model...")
            diarize_pipeline = diarize.DiarizationPipeline(use_auth_token=token, device=device)
            print("âœ… Diarization model loaded")
            
            print("ğŸ‘¥ Running speaker diarization...")
            if num_speakers:
                print(f"ğŸ¯ Specifying exact number of speakers: {num_speakers}")
                diarize_segments = diarize_pipeline(audio_path, num_speakers=num_speakers)
            else:
                diarize_segments = diarize_pipeline(audio_path)
            print("âœ… Speaker diarization completed")

            print("ğŸ¯ Assigning speakers to words...")
            result = diarize.assign_word_speakers(diarize_segments, result)
            print("âœ… Speaker assignment completed")
    else:
        print("â© Skipping diarization as requested.")

    return result
